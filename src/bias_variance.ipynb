{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_data import create_data_samples, DataSamplesType\n",
    "from linear_model import LinearModel, LinearModelType\n",
    "from design_matrix import create_design_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = create_data_samples(DataSamplesType.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_polynominal = 12\n",
    "test_size = 0.2\n",
    "n_bootstraps = 100\n",
    "\n",
    "ols_model = LinearModel(LinearModelType.OLS)\n",
    "ridge_model = LinearModel(LinearModelType.RIDGE)\n",
    "lasso_model = LinearModel(LinearModelType.LASSO)\n",
    "\n",
    "ridge_model.set_lambda(0.001)\n",
    "lasso_model.set_lambda(0.001)\n",
    "\n",
    "x = x.ravel()\n",
    "y = y.ravel()\n",
    "z = z.ravel().reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(x, y, z, test_size=test_size)\n",
    "\n",
    "errors = np.zeros((3, max_polynominal))\n",
    "biases = np.zeros((3, max_polynominal))\n",
    "variances = np.zeros((3, max_polynominal))\n",
    "\n",
    "for current_polynominal in range(1, max_polynominal + 1):\n",
    "    print(f\"at polynomial {current_polynominal} out of {max_polynominal}\")\n",
    "    \n",
    "    # Creating design matrix \n",
    "    X_train = create_design_matrix(x_train, y_train, current_polynominal)\n",
    "\n",
    "    X_test = create_design_matrix(x_test, y_test, current_polynominal)\n",
    "    \n",
    "    predictions = np.zeros((3, len(z_test), n_bootstraps))\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        X_, z_ = resample(X_train, z_train)\n",
    "        # Creating a fit for the models with the data\n",
    "        ols_model.fit(X_, z_)\n",
    "        ridge_model.fit(X_, z_)\n",
    "        lasso_model.fit(X_, z_)\n",
    "\n",
    "        # Creating predictions with the models\n",
    "        predictions[0, :, i] = ols_model.predict(X_test).ravel()\n",
    "        predictions[1, :, i] = ridge_model.predict(X_test).ravel()\n",
    "        predictions[2, :, i] = lasso_model.predict(X_test).ravel()\n",
    "\n",
    "    errors[0, current_polynominal - 1] = np.mean(np.mean((z_test - predictions[0, :])**2, axis=1, keepdims=True))\n",
    "    biases[0, current_polynominal - 1] = np.mean((z_test - np.mean(predictions[0, :], axis=1, keepdims=True))**2)\n",
    "    variances[0, current_polynominal - 1] = np.mean( np.var(predictions[0, :], axis=1, keepdims=True))\n",
    "\n",
    "    errors[1, current_polynominal - 1] = np.mean(np.mean((z_test - predictions[1, :])**2, axis=1, keepdims=True))\n",
    "    biases[1, current_polynominal - 1] = np.mean((z_test - np.mean(predictions[1, :], axis=1, keepdims=True))**2)\n",
    "    variances[1, current_polynominal - 1] = np.mean( np.var(predictions[1, :], axis=1, keepdims=True))\n",
    "\n",
    "    errors[2, current_polynominal - 1] = np.mean(np.mean((z_test - predictions[1, :])**2, axis=1, keepdims=True))\n",
    "    biases[2, current_polynominal - 1] = np.mean((z_test - np.mean(predictions[1, :], axis=1, keepdims=True))**2)\n",
    "    variances[2, current_polynominal - 1] = np.mean( np.var(predictions[1, :], axis=1, keepdims=True))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"OLS bias-variance\")\n",
    "plt.plot(errors[0, :], label=\"Error\")\n",
    "plt.plot(biases[0, :], label=\"Bias\")\n",
    "plt.plot(variances[0, :], label=\"Variance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/ols_bias_variance\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Ridge bias-variance\")\n",
    "plt.plot(errors[1, :], label=\"Error\")\n",
    "plt.plot(biases[1, :], label=\"Bias\")\n",
    "plt.plot(variances[1, :], label=\"Variance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/ridge_bias_variance\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Lasso bias-variance\")\n",
    "plt.plot(errors[1, :], label=\"Error\")\n",
    "plt.plot(biases[1, :], label=\"Bias\")\n",
    "plt.plot(variances[1, :], label=\"Variance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../figures/lasso_bias_variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dedf9e1498066a9c3f16d58765842dbf9655b275844014628f420dfe0e1cbae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
